{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75b62ead-e5f8-4c84-a2c2-e23f7cc49222",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dataset] read /data/zfr888/ljt/voc_my_data/files/VOC2007/classification_trainval.csv\n",
      "[dataset] VOC 2007 classification set=trainval number of classes=8  number of images=2525\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import os.path\n",
    "import tarfile\n",
    "from urllib.parse import urlparse\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import util\n",
    "from util import *\n",
    "import torchvision.transforms as transforms\n",
    "import transformers \n",
    "warnings.filterwarnings('ignore')\n",
    "object_categories = [\"waste_bag\",\"metal\",\"shoe\",\"plastic\",\"bottle\",\"carton\",\"lile\",\"galss\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def read_image_label(file):\n",
    "    print('[dataset] read ' + file)\n",
    "    data = dict()\n",
    "    with open(file, 'r') as f:\n",
    "        for line in f:\n",
    "            tmp = line.split(' ')\n",
    "            name = tmp[0]\n",
    "            label = int(tmp[-1])\n",
    "            data[name] = label\n",
    "            #data.append([name, label])\n",
    "            #print('%s  %d' % (name, label))\n",
    "    return data\n",
    "\n",
    "\n",
    "def read_object_labels(root, dataset, set):\n",
    "    path_labels = os.path.join(root, 'VOCdevkit', dataset, 'ImageSets', 'Main')\n",
    "    labeled_data = dict()\n",
    "    num_classes = len(object_categories)\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        file = os.path.join(path_labels, object_categories[i] + '_' + set + '.txt')\n",
    "        data = read_image_label(file)\n",
    "\n",
    "        if i == 0:\n",
    "            for (name, label) in data.items():\n",
    "                labels = np.zeros(num_classes)\n",
    "                labels[i] = label\n",
    "                labeled_data[name] = labels\n",
    "        else:\n",
    "            for (name, label) in data.items():\n",
    "                labeled_data[name][i] = label\n",
    "\n",
    "    return labeled_data\n",
    "\n",
    "\n",
    "def write_object_labels_csv(file, labeled_data):\n",
    "    # write a csv file\n",
    "    print('[dataset] write file %s' % file)\n",
    "    with open(file, 'w') as csvfile:\n",
    "        fieldnames = ['name']\n",
    "        fieldnames.extend(object_categories)\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for (name, labels) in labeled_data.items():\n",
    "            example = {'name': name}\n",
    "            for i in range(8):\n",
    "                example[fieldnames[i + 1]] = int(labels[i])\n",
    "            writer.writerow(example)\n",
    "\n",
    "    csvfile.close()\n",
    "\n",
    "\n",
    "def read_object_labels_csv(file, header=True):\n",
    "    images = []\n",
    "    num_categories = 0\n",
    "    print('[dataset] read', file)\n",
    "    with open(file, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        rownum = 0\n",
    "        for row in reader:\n",
    "            if header and rownum == 0:\n",
    "                header = row\n",
    "            else:\n",
    "                if num_categories == 0:\n",
    "                    num_categories = len(row) - 1\n",
    "                name = row[0]\n",
    "                labels = (np.asarray(row[1:num_categories + 1])).astype(np.float32)\n",
    "                labels = torch.from_numpy(labels)\n",
    "                item = (name, labels)\n",
    "                images.append(item)\n",
    "            rownum += 1\n",
    "#     import pdb; pdb.set_trace()\n",
    "    return images\n",
    "\n",
    "\n",
    "def find_images_classification(root, dataset, set):\n",
    "    path_labels = os.path.join(root, 'VOCdevkit', dataset, 'ImageSets', 'Main')\n",
    "    images = []\n",
    "    file = os.path.join(path_labels, set + '.txt')\n",
    "    with open(file, 'r') as f:\n",
    "        for line in f:\n",
    "            images.append(line)\n",
    "    return images\n",
    "\n",
    "\n",
    "##-------------------------------------------------------------------------------------------------------------------------------------------\n",
    "##-------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def extract_labels(target_list, object_categories):\n",
    "    extracted_labels = [object_categorie for index, object_categorie in zip(target_list, object_categories) if index == 1]\n",
    "    texts = []\n",
    "    \n",
    "    if not extracted_labels:\n",
    "        str = \"\"\n",
    "        texts.append(str)\n",
    "    elif len(extracted_labels) == 1:\n",
    "        str =  \", \".join(extracted_labels)\n",
    "        texts.append(str)\n",
    "    else:\n",
    "        str = \", \".join(extracted_labels[:-1]) + \" and \" + extracted_labels[-1]\n",
    "        texts.append(str)\n",
    "    return texts\n",
    "\n",
    "\n",
    "def make_textemb(texts):\n",
    "    bert_path = '/model/zfr888/dual/bert-base-uncased'##****\n",
    "    model_class, tokenizer_class, pretrained_weights = (transformers.BertModel, transformers.BertTokenizer, bert_path)\n",
    "    tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "    texts_embed = model_class.from_pretrained(pretrained_weights)\n",
    "    texts_tokenizer = [tokenizer(c) for c in texts]\n",
    "    \n",
    "    texts_input_ids = [encoding.input_ids for encoding in texts_tokenizer]\n",
    "    texts_input_ids = torch.stack(texts_input_ids)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        texts_embedding = texts_embed(texts_input_ids).last_hidden_state\n",
    "    \n",
    "    return texts_embedding\n",
    "\n",
    "\n",
    "##-------------------------------------------------------------------------------------------------------------------------------------------\n",
    "##-------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "class Voc2007Classification(data.Dataset):\n",
    "    def __init__(self, root, set, transform=None, target_transform=None, inp_name=None, adj=None):\n",
    "        self.root = root\n",
    "        self.path_devkit = os.path.join(root, 'VOCdevkit')\n",
    "        self.path_images = os.path.join(root, 'VOCdevkit', 'VOC2007', 'JPEGImages')\n",
    "        self.set = set\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # define path of csv file\n",
    "        path_csv = os.path.join(self.root, 'files', 'VOC2007')\n",
    "        # define filename of csv file\n",
    "        file_csv = os.path.join(path_csv, 'classification_' + set + '.csv')\n",
    "\n",
    "        # create the csv file if necessary\n",
    "        if not os.path.exists(file_csv):\n",
    "            if not os.path.exists(path_csv):  # create dir if necessary\n",
    "                os.makedirs(path_csv)\n",
    "            # generate csv file\n",
    "            labeled_data = read_object_labels(self.root, 'VOC2007', self.set)\n",
    "            # write csv file\n",
    "            write_object_labels_csv(file_csv, labeled_data)\n",
    "\n",
    "        self.classes = object_categories\n",
    "        self.images = read_object_labels_csv(file_csv)\n",
    "        \n",
    "        if isinstance('/code/waste/waste_zero_shot/label_file.txt', str):\n",
    "            with open('/code/waste/waste_zero_shot/label_file.txt', 'r', encoding='utf-8') as f:\n",
    "                lines = f.readlines()\n",
    "            self.categories = [{\"id\": int(line.strip().split(' ')[-1]), \"name\": line.strip().split(' ')[0]} for line in lines]\n",
    "        self.data_transforms = {\n",
    "            'trainval': transforms.Compose([transforms.Resize((224,224)),\n",
    "                                        transforms.RandomHorizontalFlip(),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                        ]),\n",
    "            'test': transforms.Compose([\n",
    "                                    transforms.Resize((224,224)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                    ])\n",
    "            }\n",
    "\n",
    "        print('[dataset] VOC 2007 classification set=%s number of classes=%d  number of images=%d' % (\n",
    "            set, len(self.classes), len(self.images)))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path, target = self.images[index]\n",
    "        img = Image.open(os.path.join(self.path_images, path + '.jpg')).convert('RGB')\n",
    "        target = target.tolist()\n",
    "        target =  [0 if x == -1 else x for x in target]\n",
    "        targets = target\n",
    "        target = np.array(target)\n",
    "        \n",
    "        img = self.data_transforms[self.set](img)\n",
    "        text = extract_labels(targets,object_categories)\n",
    "        text = \"This is an image of kitchen waste containing \" + text[0] + \".\"\n",
    "        \n",
    "        return img, target, text\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def get_number_classes(self):\n",
    "        return len(self.classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8420277-6d60-4a45-bab3-2af2994ff8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dataset] read /data/zfr888/ljt/voc_my_data/files/VOC2007/classification_test.csv\n",
      "[dataset] VOC 2007 classification set=test number of classes=8  number of images=632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|███████████████████████████████████████████████████| 79/79 [01:35<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss:0.322 train mAP:0.4087280391158704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "from dataset import *\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from torch.autograd import Variable\n",
    "from metrics import *\n",
    "from asl import *\n",
    "\n",
    "from model import *\n",
    "\n",
    "\n",
    "model = CustomCLIP(object_categories )\n",
    "model = model.cuda()\n",
    "def collate_fn(data):\n",
    "    bert_path = '/model/zfr888/dual/bert-base-uncased'  # 指定 BERT 模型路径\n",
    "    model_class, tokenizer_class, pretrained_weights = (transformers.BertModel, transformers.BertTokenizer, bert_path)\n",
    "    tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "\n",
    "    \n",
    "    inputs = [i[0] for i in data]\n",
    "    labels = [i[1] for i in data]\n",
    "    sents = [i[2] for i in data]\n",
    "    labels = torch.tensor(labels)\n",
    "    inputs = torch.tensor([item.cpu().detach().numpy() for item in inputs]).cuda()\n",
    "    \n",
    "    #编码\n",
    "    data = tokenizer.batch_encode_plus(batch_text_or_text_pairs=sents,\n",
    "                                   truncation=True,\n",
    "                                   padding='max_length',\n",
    "                                   max_length=32,\n",
    "                                   return_tensors='pt',\n",
    "                                   return_length=True)\n",
    "\n",
    "    #input_ids:编码之后的数字\n",
    "    #attention_mask:是补零的位置是0,其他位置是1\n",
    "    input_ids = data['input_ids']\n",
    "    attention_mask = data['attention_mask']\n",
    "    token_type_ids = data['token_type_ids']\n",
    "\n",
    "    return input_ids, attention_mask, token_type_ids, inputs, labels\n",
    "\n",
    "###------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "train_dataset =  Voc2007Classification('/data/zfr888/ljt/voc_my_data', 'test', inp_name='data/mydata/waste_glove_word2vec.pkl')\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                                            train_dataset,\n",
    "                                            batch_size=8,\n",
    "                                            collate_fn=collate_fn,\n",
    "                                            shuffle=True,\n",
    "                                            drop_last=False\n",
    "                                        )\n",
    "\n",
    "loss_function = AsymmetricLossOptimized(gamma_neg=4, gamma_pos=0, clip=0.05, disable_torch_grad_focal_loss=True)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "model.train()\n",
    "sf = nn.Softmax(dim=1)\n",
    "running_loss = 0.0\n",
    "gt_labels = []\n",
    "predict_p = []\n",
    "for i, (input_ids, attention_mask, token_type_ids,inputs,labels) in tqdm.tqdm(enumerate(train_loader),desc=\"Processing\", ncols=100,total=len(train_loader)):\n",
    "    labels = labels.to(torch.float32)\n",
    "    labels = torch.squeeze(labels, 1)\n",
    "    inputs = Variable(inputs.cuda())\n",
    "    labels = Variable(labels.cuda())\n",
    "    input_ids = Variable(input_ids.cuda())\n",
    "    attention_mask = Variable(attention_mask.cuda())\n",
    "    token_type_ids = Variable(token_type_ids.cuda())\n",
    "    optimizer.zero_grad()     \n",
    "    outputs = model(inputs,input_ids, attention_mask, token_type_ids)\n",
    "    gt_labels.extend(labels.cpu().numpy().tolist())\n",
    "    predict_p.extend(sf(outputs).cpu().detach().numpy())\n",
    "\n",
    "    loss = loss_function(outputs, labels)\n",
    "    # print(\"---***loss***---:{}\".format(loss))\n",
    "            # print(loss)\n",
    "    running_loss += loss.data.item()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "mAP, APs = eval_map(predict_p, gt_labels)\n",
    "print(\" loss:{:.3f} train mAP:{}\".format(loss, mAP)) \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e37cffad-aec5-471a-a8a9-f2db0c665392",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '，' (U+FF0C) (1264399372.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [8]\u001b[0;36m\u001b[0m\n\u001b[0;31m    train_map=[0.7，0.5，0.6]\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '，' (U+FF0C)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "train_map=[0.7,0.5,0.6]\n",
    "test_map=[0.8,0.9,0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45436263-d3f8-49ac-af0b-d711e833f5fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
